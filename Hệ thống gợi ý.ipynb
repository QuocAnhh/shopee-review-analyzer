{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hệ thống thông tin gợi ý bình luận \n",
    "Cấu Trúc File Code\n",
    "\n",
    "data_loader.py: tải dữ liệu\n",
    "\n",
    "preprocessing.py: xử lý NLP tiếng Việt\n",
    "\n",
    "topic_modeling.py: LDA\n",
    "\n",
    "summarizer.py: TextRank\n",
    "\n",
    "app.py: giao diện demo hoặc lưu ra file JSON/CSV mới"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Xây dựng các hệ thống Recommender Systems**\n",
    "---\n",
    "\n",
    "* **Hệ thống đề xuất dựa trên nội dung (Content-based recommenders):** Hệ thống này sẽ gợi ý các bình luận  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Khảo sát dữ liệu từ file đã xử lý NLP _processed_shopee_reviews.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>rating</th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "      <th>comments_processed</th>\n",
       "      <th>comments_clear_link</th>\n",
       "      <th>comments_clear_punctuation</th>\n",
       "      <th>comments_clear_special</th>\n",
       "      <th>comments_cleaned</th>\n",
       "      <th>comments_normalized</th>\n",
       "      <th>clean_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thanhngannehehe</td>\n",
       "      <td>5</td>\n",
       "      <td>Áo màu sắc đẹp, vải dày dặn, đường may tinh tế...</td>\n",
       "      <td>1</td>\n",
       "      <td>áo màu_sắc_đẹp , vải dày_dặn , đường may tinh_...</td>\n",
       "      <td>Áo màu sắc đẹp, vải dày dặn, đường may tinh tế...</td>\n",
       "      <td>Áo màu sắc đẹp vải dày dặn đường may tinh tế f...</td>\n",
       "      <td>o m u s c   p  v i d y d n     ng may tinh t ...</td>\n",
       "      <td>o m u s c   p v i d y d n    ng may tinh t  f...</td>\n",
       "      <td>Áo màu sắc đẹp, vải dày dặn, đường may tinh tế...</td>\n",
       "      <td>áo vải đường may form áo kg mặc vừa nha giao h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thu_nv1985</td>\n",
       "      <td>5</td>\n",
       "      <td>Chất liệu:tốt\\nĐúng với mô tả:sản phẩm đúng mô...</td>\n",
       "      <td>1</td>\n",
       "      <td>chất_liệu : tốt đúng mô_tả : sản_phẩm đúng mô_...</td>\n",
       "      <td>Chất liệu:tốt\\nĐúng với mô tả:sản phẩm đúng mô...</td>\n",
       "      <td>Chất liệutốt\\nĐúng với mô tảsản phẩm đúng mô t...</td>\n",
       "      <td>Ch t li u t t   ng v i m  t  s n ph m   ng m  ...</td>\n",
       "      <td>ch t li ut t   ng v i m  t s n ph m   ng m  t ...</td>\n",
       "      <td>Chất liệu:tốt Đúng với mô tả:sản phẩm đúng mô ...</td>\n",
       "      <td>tốt đúng đúng chuẩn đẹp hàng shop giao hàng nhanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thanhthao5000</td>\n",
       "      <td>5</td>\n",
       "      <td>Màu sắc:đỏ\\nĐúng với mô tả:đúng\\n\\nMình cái 1m...</td>\n",
       "      <td>1</td>\n",
       "      <td>màu_sắc : đỏ đúng mô_tả : đúng cái 1 m65 nặng ...</td>\n",
       "      <td>Màu sắc:đỏ\\nĐúng với mô tả:đúng\\n\\nMình cái 1m...</td>\n",
       "      <td>Màu sắcđỏ\\nĐúng với mô tảđúng\\n\\nMình cái 1m65...</td>\n",
       "      <td>M u s c      ng v i m  t    ng  M nh c i  m   ...</td>\n",
       "      <td>m u s c     ng v i m  t   ng  m nh c i  m   n ...</td>\n",
       "      <td>Màu sắc:đỏ Đúng với mô tả:đúng Mình cái 1m65 n...</td>\n",
       "      <td>đỏ đúng đúng mình cái nặng mặc xl vừa sít luôn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thomai356</td>\n",
       "      <td>5</td>\n",
       "      <td>Màu sắc:tim than\\nĐúng với mô tả:đúng với hình...</td>\n",
       "      <td>1</td>\n",
       "      <td>màu_sắc : tim than đúng mô_tả : đúng hình_ảnh ...</td>\n",
       "      <td>Màu sắc:tim than\\nĐúng với mô tả:đúng với hình...</td>\n",
       "      <td>Màu sắctim than\\nĐúng với mô tảđúng với hình ả...</td>\n",
       "      <td>M u s c tim than   ng v i m  t    ng v i h nh ...</td>\n",
       "      <td>m u s ctim than   ng v i m  t   ng v i h nh  n...</td>\n",
       "      <td>Màu sắc:tim than Đúng với mô tả:đúng với hình ...</td>\n",
       "      <td>tim than đúng đúng vai gio mua chồng màu đẹp x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b*****6</td>\n",
       "      <td>5</td>\n",
       "      <td>Đúng với mô tả:ok\\nMàu sắc:tím than\\nChất liệu...</td>\n",
       "      <td>1</td>\n",
       "      <td>đúng mô_tả : ok màu_sắc : tím than chất_liệu :...</td>\n",
       "      <td>Đúng với mô tả:ok\\nMàu sắc:tím than\\nChất liệu...</td>\n",
       "      <td>Đúng với mô tảok\\nMàu sắctím than\\nChất liệugi...</td>\n",
       "      <td>ng v i m  t  ok M u s c t m than Ch t li u g...</td>\n",
       "      <td>ng v i m  t ok m u s ct m than ch t li ugi n...</td>\n",
       "      <td>Đúng với mô tả:ok Màu sắc:tím than Chất liệu:g...</td>\n",
       "      <td>đúng ok giống vải dù hàng yody khỏi phải nói n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p*****4</td>\n",
       "      <td>5</td>\n",
       "      <td>Chất liệu:gió\\nMàu sắc:ghi\\nĐúng với mô tả:ok\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>chất_liệu : gió màu_sắc : ghi đúng mô_tả : ok ...</td>\n",
       "      <td>Chất liệu:gió\\nMàu sắc:ghi\\nĐúng với mô tả:ok\\...</td>\n",
       "      <td>Chất liệugió\\nMàu sắcghi\\nĐúng với mô tảok\\n\\n...</td>\n",
       "      <td>Ch t li u gi  M u s c ghi   ng v i m  t  ok  s...</td>\n",
       "      <td>ch t li ugi  m u s cghi   ng v i m  t ok  s n ...</td>\n",
       "      <td>Chất liệu:gió Màu sắc:ghi Đúng với mô tả:ok sả...</td>\n",
       "      <td>gió ghi đúng ok đúng vải gió giữ ấm tốt màu ck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ngatran2191</td>\n",
       "      <td>5</td>\n",
       "      <td>Đúng với mô tả:đúng\\nMàu sắc:xanh than\\nChất l...</td>\n",
       "      <td>1</td>\n",
       "      <td>đúng mô_tả : đúng màu_sắc : xanh than chất_liệ...</td>\n",
       "      <td>Đúng với mô tả:đúng\\nMàu sắc:xanh than\\nChất l...</td>\n",
       "      <td>Đúng với mô tảđúng\\nMàu sắcxanh than\\nChất liệ...</td>\n",
       "      <td>ng v i m  t    ng M u s c xanh than Ch t li ...</td>\n",
       "      <td>ng v i m  t   ng m u s cxanh than ch t li up...</td>\n",
       "      <td>Đúng với mô tả:đúng Màu sắc:xanh than Chất liệ...</td>\n",
       "      <td>đúng đúng xanh than polyeste nhìn đường may kh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u2at248y3q</td>\n",
       "      <td>5</td>\n",
       "      <td>Màu sắc:tim than\\nChất liệu:mát\\nĐúng với mô t...</td>\n",
       "      <td>1</td>\n",
       "      <td>màu_sắc : tim than chất_liệu : mát đúng mô_tả ...</td>\n",
       "      <td>Màu sắc:tim than\\nChất liệu:mát\\nĐúng với mô t...</td>\n",
       "      <td>Màu sắctim than\\nChất liệumát\\nĐúng với mô tảđ...</td>\n",
       "      <td>M u s c tim than Ch t li u m t   ng v i m  t  ...</td>\n",
       "      <td>m u s ctim than ch t li um t   ng v i m  t   n...</td>\n",
       "      <td>Màu sắc:tim than Chất liệu:mát Đúng với mô tả:...</td>\n",
       "      <td>tim than mát đúng đúng giao tới khoảng ngày mà...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sumisony</td>\n",
       "      <td>5</td>\n",
       "      <td>Chất liệu:ok\\nMàu sắc:ok\\nĐúng với mô tả:ok\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>chất_liệu : ok màu_sắc : ok đúng mô_tả : ok hà...</td>\n",
       "      <td>Chất liệu:ok\\nMàu sắc:ok\\nĐúng với mô tả:ok\\n\\...</td>\n",
       "      <td>Chất liệuok\\nMàu sắcok\\nĐúng với mô tảok\\n\\nHà...</td>\n",
       "      <td>Ch t li u ok M u s c ok   ng v i m  t  ok  H n...</td>\n",
       "      <td>ch t li uok m u s cok   ng v i m  t ok  h ng d...</td>\n",
       "      <td>Chất liệu:ok Màu sắc:ok Đúng với mô tả:ok Hàng...</td>\n",
       "      <td>ok ok đúng ok hàng màu đẹp cản gió trượt nước ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>danphuong.tran</td>\n",
       "      <td>5</td>\n",
       "      <td>Chất liệu:Đẹp , thoáng\\nMàu sắc:màu đen đậm\\nĐ...</td>\n",
       "      <td>1</td>\n",
       "      <td>chất_liệu : đẹp , thoáng màu_sắc : màu đen đậm...</td>\n",
       "      <td>Chất liệu:Đẹp , thoáng\\nMàu sắc:màu đen đậm\\nĐ...</td>\n",
       "      <td>Chất liệuĐẹp  thoáng\\nMàu sắcmàu đen đậm\\nĐúng...</td>\n",
       "      <td>Ch t li u   p   tho ng M u s c m u  en   m   n...</td>\n",
       "      <td>ch t li u  p  tho ng m u s cm u  en   m   ng v...</td>\n",
       "      <td>Chất liệu:Đẹp , thoáng Màu sắc:màu đen đậm Đún...</td>\n",
       "      <td>đẹp thoáng màu đúng đúng lời ship giao nhanh m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username  rating                                           comments   \n",
       "0  thanhngannehehe       5  Áo màu sắc đẹp, vải dày dặn, đường may tinh tế...  \\\n",
       "1       thu_nv1985       5  Chất liệu:tốt\\nĐúng với mô tả:sản phẩm đúng mô...   \n",
       "2    thanhthao5000       5  Màu sắc:đỏ\\nĐúng với mô tả:đúng\\n\\nMình cái 1m...   \n",
       "3        thomai356       5  Màu sắc:tim than\\nĐúng với mô tả:đúng với hình...   \n",
       "4          b*****6       5  Đúng với mô tả:ok\\nMàu sắc:tím than\\nChất liệu...   \n",
       "5          p*****4       5  Chất liệu:gió\\nMàu sắc:ghi\\nĐúng với mô tả:ok\\...   \n",
       "6      ngatran2191       5  Đúng với mô tả:đúng\\nMàu sắc:xanh than\\nChất l...   \n",
       "7       u2at248y3q       5  Màu sắc:tim than\\nChất liệu:mát\\nĐúng với mô t...   \n",
       "8         sumisony       5  Chất liệu:ok\\nMàu sắc:ok\\nĐúng với mô tả:ok\\n\\...   \n",
       "9   danphuong.tran       5  Chất liệu:Đẹp , thoáng\\nMàu sắc:màu đen đậm\\nĐ...   \n",
       "\n",
       "   label                                 comments_processed   \n",
       "0      1  áo màu_sắc_đẹp , vải dày_dặn , đường may tinh_...  \\\n",
       "1      1  chất_liệu : tốt đúng mô_tả : sản_phẩm đúng mô_...   \n",
       "2      1  màu_sắc : đỏ đúng mô_tả : đúng cái 1 m65 nặng ...   \n",
       "3      1  màu_sắc : tim than đúng mô_tả : đúng hình_ảnh ...   \n",
       "4      1  đúng mô_tả : ok màu_sắc : tím than chất_liệu :...   \n",
       "5      1  chất_liệu : gió màu_sắc : ghi đúng mô_tả : ok ...   \n",
       "6      1  đúng mô_tả : đúng màu_sắc : xanh than chất_liệ...   \n",
       "7      1  màu_sắc : tim than chất_liệu : mát đúng mô_tả ...   \n",
       "8      1  chất_liệu : ok màu_sắc : ok đúng mô_tả : ok hà...   \n",
       "9      1  chất_liệu : đẹp , thoáng màu_sắc : màu đen đậm...   \n",
       "\n",
       "                                 comments_clear_link   \n",
       "0  Áo màu sắc đẹp, vải dày dặn, đường may tinh tế...  \\\n",
       "1  Chất liệu:tốt\\nĐúng với mô tả:sản phẩm đúng mô...   \n",
       "2  Màu sắc:đỏ\\nĐúng với mô tả:đúng\\n\\nMình cái 1m...   \n",
       "3  Màu sắc:tim than\\nĐúng với mô tả:đúng với hình...   \n",
       "4  Đúng với mô tả:ok\\nMàu sắc:tím than\\nChất liệu...   \n",
       "5  Chất liệu:gió\\nMàu sắc:ghi\\nĐúng với mô tả:ok\\...   \n",
       "6  Đúng với mô tả:đúng\\nMàu sắc:xanh than\\nChất l...   \n",
       "7  Màu sắc:tim than\\nChất liệu:mát\\nĐúng với mô t...   \n",
       "8  Chất liệu:ok\\nMàu sắc:ok\\nĐúng với mô tả:ok\\n\\...   \n",
       "9  Chất liệu:Đẹp , thoáng\\nMàu sắc:màu đen đậm\\nĐ...   \n",
       "\n",
       "                          comments_clear_punctuation   \n",
       "0  Áo màu sắc đẹp vải dày dặn đường may tinh tế f...  \\\n",
       "1  Chất liệutốt\\nĐúng với mô tảsản phẩm đúng mô t...   \n",
       "2  Màu sắcđỏ\\nĐúng với mô tảđúng\\n\\nMình cái 1m65...   \n",
       "3  Màu sắctim than\\nĐúng với mô tảđúng với hình ả...   \n",
       "4  Đúng với mô tảok\\nMàu sắctím than\\nChất liệugi...   \n",
       "5  Chất liệugió\\nMàu sắcghi\\nĐúng với mô tảok\\n\\n...   \n",
       "6  Đúng với mô tảđúng\\nMàu sắcxanh than\\nChất liệ...   \n",
       "7  Màu sắctim than\\nChất liệumát\\nĐúng với mô tảđ...   \n",
       "8  Chất liệuok\\nMàu sắcok\\nĐúng với mô tảok\\n\\nHà...   \n",
       "9  Chất liệuĐẹp  thoáng\\nMàu sắcmàu đen đậm\\nĐúng...   \n",
       "\n",
       "                              comments_clear_special   \n",
       "0   o m u s c   p  v i d y d n     ng may tinh t ...  \\\n",
       "1  Ch t li u t t   ng v i m  t  s n ph m   ng m  ...   \n",
       "2  M u s c      ng v i m  t    ng  M nh c i  m   ...   \n",
       "3  M u s c tim than   ng v i m  t    ng v i h nh ...   \n",
       "4    ng v i m  t  ok M u s c t m than Ch t li u g...   \n",
       "5  Ch t li u gi  M u s c ghi   ng v i m  t  ok  s...   \n",
       "6    ng v i m  t    ng M u s c xanh than Ch t li ...   \n",
       "7  M u s c tim than Ch t li u m t   ng v i m  t  ...   \n",
       "8  Ch t li u ok M u s c ok   ng v i m  t  ok  H n...   \n",
       "9  Ch t li u   p   tho ng M u s c m u  en   m   n...   \n",
       "\n",
       "                                    comments_cleaned   \n",
       "0   o m u s c   p v i d y d n    ng may tinh t  f...  \\\n",
       "1  ch t li ut t   ng v i m  t s n ph m   ng m  t ...   \n",
       "2  m u s c     ng v i m  t   ng  m nh c i  m   n ...   \n",
       "3  m u s ctim than   ng v i m  t   ng v i h nh  n...   \n",
       "4    ng v i m  t ok m u s ct m than ch t li ugi n...   \n",
       "5  ch t li ugi  m u s cghi   ng v i m  t ok  s n ...   \n",
       "6    ng v i m  t   ng m u s cxanh than ch t li up...   \n",
       "7  m u s ctim than ch t li um t   ng v i m  t   n...   \n",
       "8  ch t li uok m u s cok   ng v i m  t ok  h ng d...   \n",
       "9  ch t li u  p  tho ng m u s cm u  en   m   ng v...   \n",
       "\n",
       "                                 comments_normalized   \n",
       "0  Áo màu sắc đẹp, vải dày dặn, đường may tinh tế...  \\\n",
       "1  Chất liệu:tốt Đúng với mô tả:sản phẩm đúng mô ...   \n",
       "2  Màu sắc:đỏ Đúng với mô tả:đúng Mình cái 1m65 n...   \n",
       "3  Màu sắc:tim than Đúng với mô tả:đúng với hình ...   \n",
       "4  Đúng với mô tả:ok Màu sắc:tím than Chất liệu:g...   \n",
       "5  Chất liệu:gió Màu sắc:ghi Đúng với mô tả:ok sả...   \n",
       "6  Đúng với mô tả:đúng Màu sắc:xanh than Chất liệ...   \n",
       "7  Màu sắc:tim than Chất liệu:mát Đúng với mô tả:...   \n",
       "8  Chất liệu:ok Màu sắc:ok Đúng với mô tả:ok Hàng...   \n",
       "9  Chất liệu:Đẹp , thoáng Màu sắc:màu đen đậm Đún...   \n",
       "\n",
       "                                      clean_comments  \n",
       "0  áo vải đường may form áo kg mặc vừa nha giao h...  \n",
       "1  tốt đúng đúng chuẩn đẹp hàng shop giao hàng nhanh  \n",
       "2  đỏ đúng đúng mình cái nặng mặc xl vừa sít luôn...  \n",
       "3  tim than đúng đúng vai gio mua chồng màu đẹp x...  \n",
       "4  đúng ok giống vải dù hàng yody khỏi phải nói n...  \n",
       "5  gió ghi đúng ok đúng vải gió giữ ấm tốt màu ck...  \n",
       "6  đúng đúng xanh than polyeste nhìn đường may kh...  \n",
       "7  tim than mát đúng đúng giao tới khoảng ngày mà...  \n",
       "8  ok ok đúng ok hàng màu đẹp cản gió trượt nước ...  \n",
       "9  đẹp thoáng màu đúng đúng lời ship giao nhanh m...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Đọc dữ liệu từ file đã upload: processed_shopee_reviews.csv\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'processed_shopee_reviews.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dựa vào bảng số liệu trên ta có:\n",
    "*   clean_comments — đây là văn bản đã chuẩn hóa và loại bỏ ký tự thừa\n",
    "\n",
    "Do đó, mình sẽ viết trọn bộ mã hoàn chỉnh gồm 5 mục"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: DeprecationWarning: invalid escape sequence '\\w'\n",
      "<>:17: DeprecationWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\DINH THI TRANG\\AppData\\Local\\Temp\\ipykernel_28332\\2152127937.py:17: DeprecationWarning: invalid escape sequence '\\w'\n",
      "  \"preprocessing.py\": '''\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/data/project_nlp\\\\data_loader.py',\n",
       " '/data/project_nlp\\\\preprocessing.py',\n",
       " '/data/project_nlp\\\\topic_modeling.py',\n",
       " '/data/project_nlp\\\\summarizer.py',\n",
       " '/data/project_nlp\\\\main.py',\n",
       " '/data/project_nlp\\\\requirements.txt']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tạo toàn bộ mã nguồn thành các file Python lưu trong thư mục /data/project_nlp\n",
    "import os\n",
    "\n",
    "base_path = \"/data/project_nlp\"\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "files_content = {\n",
    "    \"data_loader.py\": '''\n",
    "import pandas as pd\n",
    "\n",
    "def load_reviews(path='processed_shopee_reviews.csv'):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.dropna(subset=['clean_comments'])\n",
    "    return df\n",
    "''',\n",
    "\n",
    "    \"preprocessing.py\": '''\n",
    "from underthesea import word_tokenize\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\\\s+', ' ', text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "def tokenize_vi(text):\n",
    "    return word_tokenize(text, format=\"text\").split()\n",
    "\n",
    "def preprocess_reviews(df, column='clean_comments'):\n",
    "    df['cleaned'] = df[column].apply(clean_text)\n",
    "    df['tokens'] = df['cleaned'].apply(tokenize_vi)\n",
    "    return df\n",
    "''',\n",
    "\n",
    "    \"topic_modeling.py\": '''\n",
    "from gensim import corpora, models\n",
    "import pyLDAvis.gensim_models\n",
    "import pyLDAvis\n",
    "\n",
    "def build_lda_model(token_lists, num_topics=5, passes=10):\n",
    "    dictionary = corpora.Dictionary(token_lists)\n",
    "    corpus = [dictionary.doc2bow(text) for text in token_lists]\n",
    "    lda_model = models.LdaModel(corpus=corpus, id2word=dictionary,\n",
    "                                num_topics=num_topics, passes=passes,\n",
    "                                random_state=42)\n",
    "    return lda_model, corpus, dictionary\n",
    "\n",
    "def show_topics(lda_model, num_words=10):\n",
    "    topics = lda_model.print_topics(num_words=num_words)\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "\n",
    "def visualize_lda(lda_model, corpus, dictionary):\n",
    "    vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
    "    pyLDAvis.save_html(vis, 'lda_vietnamese.html')\n",
    "''',\n",
    "\n",
    "    \"summarizer.py\": '''\n",
    "from summa.summarizer import summarize\n",
    "\n",
    "def summarize_review(text, ratio=0.3):\n",
    "    try:\n",
    "        return summarize(text, ratio=ratio)\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def summarize_all(df, column='clean_comments'):\n",
    "    df['summary'] = df[column].apply(lambda x: summarize_review(x, ratio=0.3))\n",
    "    return df\n",
    "''',\n",
    "\n",
    "    \"main.py\": '''\n",
    "from data_loader import load_reviews\n",
    "from preprocessing import preprocess_reviews\n",
    "from topic_modeling import build_lda_model, show_topics, visualize_lda\n",
    "from summarizer import summarize_all\n",
    "\n",
    "def main():\n",
    "    df = load_reviews('processed_shopee_reviews.csv')\n",
    "    df = preprocess_reviews(df, column='clean_comments')\n",
    "\n",
    "    lda_model, corpus, dictionary = build_lda_model(df['tokens'].tolist(), num_topics=5)\n",
    "    show_topics(lda_model)\n",
    "    visualize_lda(lda_model, corpus, dictionary)\n",
    "\n",
    "    df = summarize_all(df, column='clean_comments')\n",
    "    df[['clean_comments', 'summary']].to_csv('output_summary.csv', index=False)\n",
    "    print(\" Hoàn thành. File kết quả: output_summary.csv, LDA visualization: lda_vietnamese.html\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "''',\n",
    "\n",
    "    \"requirements.txt\": '''\n",
    "pandas\n",
    "underthesea\n",
    "gensim\n",
    "summa\n",
    "pyLDAvis\n",
    "'''\n",
    "}\n",
    "\n",
    "# Ghi từng file vào thư mục\n",
    "file_paths = []\n",
    "for filename, content in files_content.items():\n",
    "    full_path = os.path.join(base_path, filename)\n",
    "    with open(full_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content.strip())\n",
    "    file_paths.append(full_path)\n",
    "\n",
    "file_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Di chuyển file processed_shopee_reviews.csv vào cùng thư mục chứa mã nguồn.\n",
    "\n",
    "* Cài thư viện:\n",
    "    pip install -r requirements.txt\n",
    "\n",
    "* Chạy main.py:\n",
    "    python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Nén toàn bộ thư mục chứa mã nguồn thành file zip\n",
    "zip_path = \"/data/project_nlp.zip\"\n",
    "shutil.make_archive(base_name=zip_path.replace(\".zip\", \"\"), format='zip', root_dir=\"/data/project_nlp\")\n",
    "\n",
    "zip_path\n",
    "# Tải file zip về máy\n",
    "import shutil  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phân tích chủ đề (Topic Modeling với LDA)**\n",
    "* 1.Dùng thư viện gensim để huấn luyện mô hình LDA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Xử lý văn bản từ file processed_shopee_reviews có thể dừng thư viện underthesea hoặc VnCorreNPL để xử lý tiếng việt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data_loader\n",
    "* Preprocessing\n",
    "* Summarizer\n",
    "    * Xử lý văn bản ngắn\n",
    "    * Xử lý ngoại lệ\n",
    "    \n",
    "        Kiểm tra độ dài văn bản: Nếu văn bản có ít hơn 5 từ, không áp dụng summarize, tránh trường hợp không thể tóm tắt văn bản quá ngắn.\n",
    "\n",
    "        Xử lý lỗi cụ thể hơn: In ra thông báo lỗi chi tiết nếu có sự cố khi gọi summarize\n",
    "* topic_moderling\n",
    "* main\n",
    "\n",
    " **Tóm tắt tự động với TextRank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORT THƯ VIỆN\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from underthesea import word_tokenize\n",
    "from summa.summarizer import summarize\n",
    "from gensim import corpora, models\n",
    "import pyLDAvis.gensim_models\n",
    "import pyLDAvis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2. LOAD DỮ LIỆU\n",
    "def load_reviews(path='processed_shopee_reviews.csv'):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\" File {path} không tồn tại.\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    if 'clean_comments' not in df.columns:\n",
    "        print(\" Cột 'clean_comments' không tồn tại trong dữ liệu.\")\n",
    "        return None\n",
    "    \n",
    "    df = df.dropna(subset=['clean_comments'])\n",
    "    print(f\" Đã tải {len(df)} dòng dữ liệu từ {path}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. TIỀN XỬ LÝ VĂN BẢN của bình luận\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)     # Xoá ký tự đặc biệt\n",
    "    text = re.sub(r'\\s+', ' ', text)         # Xoá khoảng trắng thừa\n",
    "    return text.strip().lower()\n",
    "\n",
    "def tokenize_vi(text):\n",
    "    return word_tokenize(text, format=\"text\").split()\n",
    "\n",
    "def preprocess_reviews(df, column='clean_comments'):\n",
    "    df['cleaned'] = df[column].apply(clean_text)\n",
    "    df['tokens'] = df['cleaned'].apply(tokenize_vi)\n",
    "    print(\" Đã tiền xử lý xong văn bản.\")\n",
    "    return df\n",
    "\n",
    "# 4. MÔ HÌNH CHỦ ĐỀ LDA\n",
    "def build_lda_model(token_lists, num_topics=5, passes=10):\n",
    "    dictionary = corpora.Dictionary(token_lists)\n",
    "    corpus = [dictionary.doc2bow(text) for text in token_lists]\n",
    "    lda_model = models.LdaModel(corpus=corpus,\n",
    "                                id2word=dictionary,\n",
    "                                num_topics=num_topics,\n",
    "                                passes=passes,\n",
    "                                random_state=42)\n",
    "    return lda_model, corpus, dictionary\n",
    "\n",
    "def show_topics(lda_model, num_words=10):\n",
    "    topics = lda_model.print_topics(num_words=num_words)\n",
    "    print(\"\\n Các chủ đề được trích xuất:\")\n",
    "    for idx, topic in topics:\n",
    "        print(f\"Chủ đề {idx + 1}: {topic}\")\n",
    "\n",
    "def visualize_lda(lda_model, corpus, dictionary, filename='lda_vietnamese.html'):\n",
    "    vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
    "    pyLDAvis.save_html(vis, filename)\n",
    "    print(f\" Đã lưu kết quả trực quan hóa vào: {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. TÓM TẮT BÌNH LUẬN\n",
    "def summarize_review(text, ratio=0.3):\n",
    "    if len(text.split()) < 5:\n",
    "        return text\n",
    "    try:\n",
    "        return summarize(text, ratio=ratio)\n",
    "    except Exception as e:\n",
    "        print(f\" Lỗi khi tóm tắt: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def summarize_all(df, column='clean_comments'):\n",
    "    df['summary'] = df[column].apply(lambda x: summarize_review(x, ratio=0.3))\n",
    "    print(\" Đã tóm tắt tất cả bình luận.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Đã tải 1175 dòng dữ liệu từ processed_shopee_reviews.csv\n",
      " Đã tiền xử lý xong văn bản.\n",
      "\n",
      " Các chủ đề được trích xuất:\n",
      "Chủ đề 1: 0.042*\"nhận\" + 0.038*\"mang\" + 0.033*\"áo\" + 0.025*\"xu\" + 0.023*\"đẹp\" + 0.018*\"chỉ\" + 0.017*\"đúng\" + 0.016*\"mua\" + 0.011*\"hàng\" + 0.010*\"yody\"\n",
      "Chủ đề 2: 0.012*\"ngay\" + 0.010*\"ok\" + 0.009*\"đường\" + 0.009*\"goi\" + 0.008*\"mang\" + 0.007*\"đúng\" + 0.007*\"chi\" + 0.007*\"de\" + 0.007*\"viettel\" + 0.006*\"tran\"\n",
      "Chủ đề 3: 0.088*\"hàng\" + 0.056*\"giao\" + 0.049*\"nhanh\" + 0.042*\"đúng\" + 0.031*\"shop\" + 0.030*\"đẹp\" + 0.021*\"lần\" + 0.018*\"sẽ\" + 0.017*\"mua\" + 0.013*\"tốt\"\n",
      "Chủ đề 4: 0.084*\"đúng\" + 0.038*\"mua\" + 0.032*\"ok\" + 0.027*\"đẹp\" + 0.025*\"áo\" + 0.025*\"hàng\" + 0.019*\"tốt\" + 0.017*\"shop\" + 0.016*\"yody\" + 0.015*\"giao\"\n",
      "Chủ đề 5: 0.048*\"đẹp\" + 0.043*\"áo\" + 0.037*\"mua\" + 0.026*\"đúng\" + 0.025*\"mặc\" + 0.021*\"mình\" + 0.020*\"giá\" + 0.016*\"size\" + 0.012*\"hơn\" + 0.012*\"màu\"\n",
      " Đã lưu kết quả trực quan hóa vào: lda_vietnamese.html\n",
      " Đã tóm tắt tất cả bình luận.\n",
      " Hoàn thành toàn bộ pipeline.\n",
      " File kết quả: output_summary.csv\n",
      " File visualization: lda_vietnamese.html\n"
     ]
    }
   ],
   "source": [
    "# 6. CHẠY TOÀN BỘ QUY TRÌNH\n",
    "def main():\n",
    "    df = load_reviews('processed_shopee_reviews.csv')\n",
    "    if df is None or df.empty:\n",
    "        print(\" Không thể xử lý vì dữ liệu bị thiếu hoặc rỗng.\")\n",
    "        return\n",
    "\n",
    "    df = preprocess_reviews(df, column='clean_comments')\n",
    "\n",
    "    lda_model, corpus, dictionary = build_lda_model(df['tokens'].tolist(), num_topics=5)\n",
    "    show_topics(lda_model)\n",
    "    visualize_lda(lda_model, corpus, dictionary)\n",
    "\n",
    "    df = summarize_all(df, column='clean_comments')\n",
    "\n",
    "    df[['clean_comments', 'summary']].to_csv('output_summary.csv', index=False)\n",
    "    print(\" Hoàn thành toàn bộ pipeline.\")\n",
    "    print(\" File kết quả: output_summary.csv\")\n",
    "    print(\" File visualization: lda_vietnamese.html\")\n",
    "\n",
    "# 7. CHẠY CHƯƠNG TRÌNH\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     keywords \u001b[38;5;241m=\u001b[39m lda_model\u001b[38;5;241m.\u001b[39mprint_topic(topic_id, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview này đề cập đến \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeywords\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 14\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdominant_topic\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [get_dominant_topic(bow) \u001b[38;5;28;01mfor\u001b[39;00m bow \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcorpus\u001b[49m]\n\u001b[0;32m     15\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuggestion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdominant_topic\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(suggest)\n\u001b[0;32m     16\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_comments\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdominant_topic\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuggestion\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_suggestion.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "def get_dominant_topic(doc_bow):\n",
    "    topic_probs = lda_model.get_document_topics(doc_bow)\n",
    "    if topic_probs:\n",
    "        dominant = sorted(topic_probs, key=lambda x: -x[1])[0]\n",
    "        return dominant[0]\n",
    "    return None\n",
    "\n",
    "def suggest(topic_id):\n",
    "    if topic_id is None:\n",
    "        return \"Không xác định được chủ đề\"\n",
    "    keywords = lda_model.print_topic(topic_id, topn=3)\n",
    "    return f\"Review này đề cập đến {keywords}\"\n",
    "\n",
    "df['dominant_topic'] = [get_dominant_topic(bow) for bow in corpus]\n",
    "df['suggestion'] = df['dominant_topic'].apply(suggest)\n",
    "df[['clean_comments', 'dominant_topic', 'suggestion']].to_csv('output_suggestion.csv', index=False)\n",
    "print(\" Hoàn thành. File kết quả: output_suggestion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\DINH THI TRANG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\DINH THI TRANG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DINH THI TRANG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tokens'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Word Cloud\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m all_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tokens) \u001b[38;5;28;01mfor\u001b[39;00m tokens \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m])\n\u001b[0;32m      7\u001b[0m wordcloud \u001b[38;5;241m=\u001b[39m WordCloud(width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m, background_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m'\u001b[39m, font_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marial.ttf\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mgenerate(all_words)\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\DINH THI TRANG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3760\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3760\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3762\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\DINH THI TRANG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tokens'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Word Cloud\n",
    "all_words = ' '.join([' '.join(tokens) for tokens in df['tokens']])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', font_path='arial.ttf').generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"Word Cloud các từ phổ biến\")\n",
    "plt.show()\n",
    "\n",
    "# Biểu đồ số lượng chủ đề\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x='dominant_topic', data=df)\n",
    "plt.title(\"Phân phối các chủ đề trong review\")\n",
    "plt.xlabel(\"Chủ đề\")\n",
    "plt.ylabel(\"Số lượng\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_reviews_with_topics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Trực quan hóa & Gợi ý**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiển thị các chủ đề phổ biến dưới dạng word cloud hoặc biểu đồ.\n",
    "\n",
    "Với mỗi review, hiển thị:\n",
    "\n",
    "*   Chủ đề chính.\n",
    "*   Tóm tắt nội dung.\n",
    "*   Gợi ý cho người dùng (ví dụ: \"Review này đề cập đến chất lượng sản phẩm và giao hàng\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\DINH THI\n",
      "[nltk_data]     TRANG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\DINH THI\n",
      "[nltk_data]     TRANG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cài đặt thư viện nếu cần\n",
    "# !pip install pandas matplotlib seaborn wordcloud gensim nltk scikit-learn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora, models\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File đã được lưu tại: data\\vietnamese_stopwords.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Tạo nội dung stopwords tiếng Việt\n",
    "stopwords_vi = \"\"\"\n",
    "và\n",
    "là\n",
    "của\n",
    "có\n",
    "cho\n",
    "một\n",
    "những\n",
    "các\n",
    "đã\n",
    "đến\n",
    "trong\n",
    "khi\n",
    "với\n",
    "này\n",
    "rằng\n",
    "vì\n",
    "nên\n",
    "thì\n",
    "lại\n",
    "đó\n",
    "từ\n",
    "ra\n",
    "được\n",
    "tại\n",
    "theo\n",
    "nó\n",
    "như\n",
    "đây\n",
    "nào\n",
    "cũng\n",
    "rất\n",
    "còn\n",
    "bị\n",
    "trên\n",
    "dưới\n",
    "giữa\n",
    "vẫn\n",
    "sẽ\n",
    "đi\n",
    "lúc\n",
    "hơn\n",
    "nữa\n",
    "hay\n",
    "cả\n",
    "ai\n",
    "gì\n",
    "đâu\n",
    "vậy\n",
    "ấy\n",
    "thôi\n",
    "luôn\n",
    "vừa\n",
    "mới\n",
    "đang\n",
    "vào\n",
    "kể\n",
    "nếu\n",
    "hoặc\n",
    "để\n",
    "mà\n",
    "nhưng\n",
    "rồi\n",
    "do\n",
    "thế\n",
    "chỉ\n",
    "kia\n",
    "\"\"\".strip()\n",
    "\n",
    "# Đảm bảo thư mục tồn tại\n",
    "folder_path = \"data\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Lưu file vào thư mục\n",
    "file_path = os.path.join(folder_path, \"vietnamese_stopwords.txt\")\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(stopwords_vi)\n",
    "\n",
    "print(\"File đã được lưu tại:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc danh sách stopwords từ file\n",
    "with open(\"vietnamese_stopwords.txt\", encoding=\"utf-8\") as f:\n",
    "    stop_words = set([line.strip() for line in f.readlines()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\DINH THI\n",
      "[nltk_data]     TRANG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words \u001b[38;5;129;01mand\u001b[39;00m t \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string\u001b[38;5;241m.\u001b[39mpunctuation \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39misalpha()]\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n\u001b[1;32m---> 11\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclean_comments\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DINH THI TRANG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4631\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4521\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4522\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4523\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4527\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4530\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4630\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DINH THI TRANG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DINH THI TRANG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\DINH THI TRANG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[99], line 7\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(text):\n\u001b[1;32m----> 7\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m word_tokenize(\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m())\n\u001b[0;32m      8\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words \u001b[38;5;129;01mand\u001b[39;00m t \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string\u001b[38;5;241m.\u001b[39mpunctuation \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39misalpha()]\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [t for t in tokens if t not in stop_words and t not in string.punctuation and t.isalpha()]\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['clean_comments'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\DINH THI TRANG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\DINH THI TRANG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DINH THI TRANG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tokens'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m corpora, models\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Tạo từ điển và tập văn bản\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m dictionary \u001b[38;5;241m=\u001b[39m corpora\u001b[38;5;241m.\u001b[39mDictionary(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      5\u001b[0m corpus \u001b[38;5;241m=\u001b[39m [dictionary\u001b[38;5;241m.\u001b[39mdoc2bow(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train mô hình LDA\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DINH THI TRANG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3760\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3760\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3762\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\DINH THI TRANG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tokens'"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "# Tạo từ điển và tập văn bản\n",
    "dictionary = corpora.Dictionary(df['tokens'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['tokens']]\n",
    "\n",
    "# Train mô hình LDA\n",
    "lda_model = models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=10)\n",
    "\n",
    "# In ra các chủ đề\n",
    "for i, topic in lda_model.print_topics(num_words=5):\n",
    "    print(f\"🔸 Chủ đề {i}: {topic}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_suggestions(df):\n",
    "    # Gợi ý dựa trên chủ đề hoặc các từ khóa chính\n",
    "    df['suggestions'] = df['summary'].apply(lambda x: \"Review này đề cập đến chất lượng sản phẩm và giao hàng\" if 'chất lượng' in x else \"Review này đề cập đến các vấn đề khác.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
